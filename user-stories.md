### 1. Document Uploading and Processing ✅ COMPLETED

These stories cover the initial interaction of getting the document into the system.

* **As a User,** I want to select and upload a PDF file from my computer, **so that** the system can process it for questioning.
  - ✅ Implemented: Drag-and-drop upload component with file selection
* **As a User,** I want to see a visual confirmation (e.g., a loading bar or "Processing...") while the system is parsing and vectorizing the PDF, **so that** I know the system is working and I don't close the window.
  - ✅ Implemented: Upload progress indicator and document status display
* **As a User,** I want to receive a clear notification when my document is successfully processed and ready, **so that** I know I can begin asking questions.
  - ✅ Implemented: Document list shows status badges (ready/processing/failed)
* **As a User,** I want to be alerted with an error message if the file upload fails (e.g., it's not a PDF, it's corrupted, or too large), **so that** I can try again with a valid file.
  - ✅ Implemented: Client-side validation + server error handling with user-friendly messages

---

### 2. Querying the Document (RAG) ✅ COMPLETED

These stories define the core Q&A interaction, emphasizing the Spanish language requirement.

* **As a User,** I want to type a question in a text input box, **so that** I can request specific information from my document.
  - ✅ Implemented: Interactive chat interface with text input and message history
* **As a User,** I want to ask my questions in **Chilean Spanish** and have the system understand the nuances of my language, **so that** I can interact naturally and get accurate results from the Spanish document.
  - ✅ Implemented: OpenAI embeddings + GPT-4 with Spanish prompts
* **As a User,** I want the answers generated by the system to be **directly based** on the information present in the uploaded PDF, **so that** I can trust the answers are factual and contextually relevant.
  - ✅ Implemented: RAG architecture with similarity search and context injection
* **As a User,** I want to receive answers in clear, coherent Spanish, **so that** the information is easy to understand.
  - ✅ Implemented: System prompts configured for Spanish responses
* **As a User,** I want the system to provide **citations** (e.g., page or section references) with its answers, **so that** I can easily locate and verify the source information in the original PDF.
  - ✅ Implemented: Answers include page references and chunk metadata

---

### 3. Handling Out-of-Scope Questions ✅ COMPLETED

This section covers the requirement to guide the user when a query isn't relevant.

* **As a User,** if I ask a question that **cannot** be answered by the document's content, I want the system to inform me that the information is not available, **so that** I am not misled by a fabricated (hallucinated) answer.
  - ✅ Implemented: Similarity threshold filtering + "is_answerable" flag in responses
* **As a User,** when my question is off-topic or irrelevant, I want the system to politely **ask me to rephrase** or ask another question that is related to the document, **so that** I am guided back to a productive conversation.
  - ✅ Implemented: System prompts instruct LLM to acknowledge when information is not in document

---

### 4. Additional Features Implemented

* **Document Management**
  - ✅ View list of all uploaded documents
  - ✅ Filter chat queries by specific document
  - ✅ Delete documents and their associated chunks
  - ✅ Real-time document processing status

* **User Interface**
  - ✅ Modern, responsive React interface
  - ✅ Drag-and-drop file upload
  - ✅ Real-time chat with message history
  - ✅ Visual feedback for all operations
  - ✅ Error handling with user-friendly messages

* **Technical Implementation**
  - ✅ RESTful API with FastAPI
  - ✅ Vector similarity search with pgvector
  - ✅ Asynchronous processing
  - ✅ Docker containerization
  - ✅ Comprehensive test suite (103 tests)
